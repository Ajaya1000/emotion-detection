{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "import webbrowser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++ loadin gmmodel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 1\n",
    "\n",
    "info = {}\n",
    "\n",
    "haarcascade = \"haarcascade_frontalface_default.xml\"\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "print(\"+\"*50, \"loadin gmmodel\")\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "cascade = cv2.CascadeClassifier(haarcascade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "\treturn render_template('index.html')\n",
    "\n",
    "@app.route('/choose_singer', methods = [\"POST\"])\n",
    "def choose_singer():\n",
    "\tinfo['language'] = request.form['language']\n",
    "\tprint(info)\n",
    "\treturn render_template('choose_singer.html', data = info['language'])\n",
    "\n",
    "\n",
    "@app.route('/emotion_detect', methods=[\"POST\"])\n",
    "def emotion_detect():\n",
    "\tinfo['singer'] = request.form['singer']\n",
    "\n",
    "\tfound = False\n",
    "\n",
    "\tcap = cv2.VideoCapture(0)\n",
    "\twhile not(found):\n",
    "\t\t_, frm = cap.read()\n",
    "\t\tgray = cv2.cvtColor(frm,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t\tfaces = cascade.detectMultiScale(gray, 1.4, 1)\n",
    "\n",
    "\t\tfor x,y,w,h in faces:\n",
    "\t\t\tfound = True\n",
    "\t\t\troi = gray[y:y+h, x:x+w]\n",
    "\t\t\tcv2.imwrite(\"static/face.jpg\", roi)\n",
    "\n",
    "\troi = cv2.resize(roi, (48,48))\n",
    "\n",
    "\troi = roi/255.0\n",
    "\t\n",
    "\troi = np.reshape(roi, (1,48,48,1))\n",
    "\tprint(roi.shape)\n",
    "\n",
    "\t# prediction = \"something\"#model.predict(roi)\n",
    "\n",
    "\t# print(prediction)\n",
    "\n",
    "\t# prediction = np.argmax(prediction)\n",
    "\tprediction = \"something\"#label_map[prediction]\n",
    "\n",
    "\tcap.release()\n",
    "\n",
    "\tlink  = f\"https://www.youtube.com/results?search_query={info['singer']}+{prediction}+{info['language']}+song\"\n",
    "\twebbrowser.open(link)\n",
    "\n",
    "\treturn render_template(\"emotion_detect.html\", data=prediction, link=link)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tapp.run(debug=True, use_reloader=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = cv2.imread(\"./static/images/face.png\")\n",
    "\n",
    "cv2.imshow(\"\",image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([image_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2593263e-01 0.0000000e+00 3.8412411e-04 1.9173091e-02 3.5450661e-01\n",
      "  3.5989440e-06 1.5894599e-13]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "predicted_data.shape\n",
    "print(predicted_data)\n",
    "class_idxs = np.argmax(predicted_data, axis=-1) \n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = './static/images'\n",
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "img_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "img_generator = img_datagen.flow_from_directory(directory = image_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )\n",
    "images, classes = next(img_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 48, 48, 3), dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
