{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "import webbrowser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++ loadin gmmodel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 1\n",
    "\n",
    "info = {}\n",
    "\n",
    "haarcascade = \"haarcascade_frontalface_default.xml\"\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "print(\"+\"*50, \"loadin gmmodel\")\n",
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "cascade = cv2.CascadeClassifier(haarcascade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [20/Feb/2022 14:39:40] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Feb/2022 14:39:40] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [20/Feb/2022 14:39:49] \"POST /choose_singer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Feb/2022 14:39:49] \"GET /static/style.css HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'english'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Feb/2022 14:40:02] \"POST /emotion_detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Feb/2022 14:40:02] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [20/Feb/2022 14:40:02] \"GET /static/face.jpg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "\treturn render_template('index.html')\n",
    "\n",
    "@app.route('/choose_singer', methods = [\"POST\"])\n",
    "def choose_singer():\n",
    "\tinfo['language'] = request.form['language']\n",
    "\tprint(info)\n",
    "\treturn render_template('choose_singer.html', data = info['language'])\n",
    "\n",
    "\n",
    "@app.route('/emotion_detect', methods=[\"POST\"])\n",
    "def emotion_detect():\n",
    "\tinfo['singer'] = request.form['singer']\n",
    "\n",
    "\tfound = False\n",
    "\n",
    "\tcap = cv2.VideoCapture(0)\n",
    "\twhile not(found):\n",
    "\t\t_, frm = cap.read()\n",
    "\t\tgray = cv2.cvtColor(frm,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t\tfaces = cascade.detectMultiScale(gray, 1.4, 1)\n",
    "\t\t# print(faces)\n",
    "\t\tfor x,y,w,h in faces:\n",
    "\t\t\tfound = True\n",
    "\t\t\troi = gray[y:y+h, x:x+w]\n",
    "\t\t\tcv2.imwrite(\"static/images/face.jpg\", roi)\n",
    "\t\n",
    "\timage_input = cv2.imread(\"./static/images/face.png\")\n",
    "\tdata = np.array([image_input])\n",
    "\n",
    "\t# roi = cv2.resize(roi, (48,48))\n",
    "\n",
    "\t# roi = roi/255.0\n",
    "\t\n",
    "\t# roi = np.reshape(roi, (1,48,48,1))\n",
    "\n",
    "\tpredicted_data = model.predict(data)\n",
    "\tclass_idxs = np.argmax(predicted_data, axis=-1) \n",
    "\n",
    "\t# print(prediction)\n",
    "\n",
    "\t# prediction = np.argmax(prediction)\n",
    "\t# prediction = label_map[prediction]\n",
    "\tprediction = label_map[class_idxs[0]]\n",
    "\n",
    "\tcap.release()\n",
    "\n",
    "\tlink  = f\"https://www.youtube.com/results?search_query={info['singer']}+{prediction}+{info['language']}+song\"\n",
    "\twebbrowser.open(link)\n",
    "\n",
    "\treturn render_template(\"emotion_detect.html\", data=prediction, link=link)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tapp.run(debug=True, use_reloader=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
